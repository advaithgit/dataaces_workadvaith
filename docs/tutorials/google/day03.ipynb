{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install docx\n"
      ],
      "metadata": {
        "id": "wN7LYx9zUcLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade python-docx\n",
        "!pip install --upgrade exceptions\n"
      ],
      "metadata": {
        "id": "58qJdJ1WUkcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import heapq\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_excel('Dataset1.xlsx')\n",
        "\n",
        "# Extract content from the 'content' column\n",
        "corpus = df['content'].tolist()\n",
        "\n",
        "# TF-IDF vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
        "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
        "\n",
        "# NMF for topic modeling\n",
        "num_topics = 10\n",
        "nmf_model = NMF(n_components=num_topics, random_state=42)\n",
        "nmf_model.fit(tfidf)\n",
        "\n",
        "# Get top topics\n",
        "top_topics = []\n",
        "for topic_idx, topic in enumerate(nmf_model.components_):\n",
        "    top_keywords_idx = topic.argsort()[-5:][::-1]\n",
        "    top_keywords = [tfidf_vectorizer.get_feature_names_out()[i] for i in top_keywords_idx]\n",
        "    top_topics.append(' '.join(top_keywords))\n",
        "\n",
        "# Display top 10 most discussed topics\n",
        "print(\"Top 10 Most Discussed Topics:\")\n",
        "for i, topic in enumerate(top_topics, start=1):\n",
        "    print(f\"{i}. {topic}\")\n",
        "\n",
        "# Ask user for a keyword\n",
        "keyword = input(\"Enter a keyword to find related content: \")\n",
        "\n",
        "# Filter content based on the entered keyword\n",
        "relevant_content = df[df['content'].str.contains(keyword)]['content'].tolist()\n",
        "\n",
        "# Combine all relevant content into a single text\n",
        "combined_content = \"\\n\".join(relevant_content)\n",
        "\n",
        "# Calculate TF-IDF scores for sentences\n",
        "sentence_tfidf = tfidf_vectorizer.transform([combined_content]).toarray()\n",
        "\n",
        "# Calculate cosine similarity between sentences and combined content\n",
        "cosine_similarities = cosine_similarity(tfidf.toarray(), sentence_tfidf)\n",
        "\n",
        "# Calculate average cosine similarity for each sentence\n",
        "sentence_scores = np.mean(cosine_similarities, axis=1)\n",
        "\n",
        "# Rank sentences by score\n",
        "top_sentence_indices = heapq.nlargest(500, range(len(sentence_scores)), sentence_scores.take)\n",
        "\n",
        "# Extract top sentences and create the summary\n",
        "extractive_summary = '\\n'.join([corpus[i] for i in top_sentence_indices])\n",
        "\n",
        "# Clean the summary by removing extra spaces and newlines\n",
        "cleaned_summary = re.sub(r'\\s+', ' ', extractive_summary).strip()\n",
        "\n",
        "# Split the summary into words\n",
        "words = cleaned_summary.split(' ')\n",
        "\n",
        "# Initialize variables\n",
        "current_length = 0\n",
        "limited_summary = []\n",
        "\n",
        "# Limit the summary to less than 500 words\n",
        "for word in words:\n",
        "    if current_length + len(word) + 1 <= 500:\n",
        "        limited_summary.append(word)\n",
        "        current_length += len(word) + 1\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Join the limited summary words back into a string\n",
        "final_summary = ' '.join(limited_summary)\n",
        "\n",
        "# Print the final summary\n",
        "print(f\"\\nExtractive Summary for All Content Related to '{keyword}':\\n{final_summary}\")\n"
      ],
      "metadata": {
        "id": "3jwGE8mpAKLz",
        "outputId": "b7040970-3fe0-4f32-9564-5d7b5631251a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Most Discussed Topics:\n",
            "1. ai microsoft cloud google data\n",
            "2. crypto ftx assets bitcoin asset\n",
            "3. reuters photo file editing thomson\n",
            "4. bnpl credit consumers pay cfpb\n",
            "5. bank cbdc digital central currency\n",
            "6. law360 login case article 2farticles\n",
            "7. company year said million billion\n",
            "8. payments payment banking fintech digital\n",
            "9. blockchain nfts nft metaverse web3\n",
            "10. binance ftx exchange voyager zhao\n",
            "Enter a keyword to find related content: google\n",
            "\n",
            "Extractive Summary for All Content Related to 'google':\n",
            "NEW YORK & SUNNYVALE, Calif.- Through a strategic expansion of their relationship, Accenture (NYSE: ACN) and Google Cloud will help organizations reinvent their businesses with generative AI to unlock new growth opportunities, supported by substantial new investments by Accenture. Today’s expansion builds on Accenture’s recently announced $3 billion investment in AI . Together, Accenture and Google Cloud will help organizations use generative AI to create new opportunities to drive next-level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install summarizer"
      ],
      "metadata": {
        "id": "YtFruPSi5ahy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert-extractive-summarizer\n"
      ],
      "metadata": {
        "id": "-apk2tTP6D2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "6loYPSW0fUSS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}