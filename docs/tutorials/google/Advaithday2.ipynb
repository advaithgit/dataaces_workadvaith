{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "summarizer = pipeline(\"summarization\")\n",
        "text = \"\"\"\n",
        "Flexible and effective pipelined processors have been developed as a result of the demand for high-performance computing systems, notably for real-time AI and IoT applications. Flexible Thermally Stable Pipelines Ga-As processors ought to emerge as a possible improvement in energy efficiency. When compared to Si-based processors, Ga-As technology has benefits including high speed, low power consumption, and thermal stability. Energy efficiency may be maximized by the design of flexible pipelined architectures, which includes clock speed and pipeline design. Pipeline design modifications and thermal management strategies can reduce performance deterioration brought on by heat. In conclusion, flexible thermally stable pipelines Ga-As processors, which have benefits over Si-based processors and room for optimisation, show promise for improving energy efficiency in real-time AI and IoT applications.\n",
        "This review of the literature offers useful information to researchers and business people interested in examining how thermally stable flexible pipelined Ga-As processors might improve energy efficiency in real-time AI and IoT applications. The paper establishes the exceptional performance and energy-saving capabilities of Ga-As processors by conducting a thorough analysis of the benefits offered by Ga-As technology, talking about the variables that affect energy efficiency, suggesting solutions to ensure thermal stability, and presenting experimental results. It is a thorough resource that assists readers in comprehending the possibilities of Ga-As technology and points out directions for future study as well as prospective applications in a variety of fields.\n",
        "\"\"\"\n",
        "summarizer(text, max_length=130, min_length=30, do_sample=False)\n"
      ],
      "metadata": {
        "id": "9Y7jZIv2WOeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load summarization pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\", do_sample=False)\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    pdf = PyPDF2.PdfReader(pdf_path)\n",
        "    for page in pdf.pages:\n",
        "        text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def main():\n",
        "    pdf_path = \"Litrev.pdf\"  # Replace with your PDF file path\n",
        "\n",
        "    extracted_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    # Check input length before summarization\n",
        "    if len(extracted_text) <= summarizer.model.config.max_position_embeddings:\n",
        "        summary = summarizer(extracted_text, max_length=500, min_length=300, do_sample=False)\n",
        "        print(\"\\nSummarized Text:\")\n",
        "        print(summary[0]['summary_text'])\n",
        "    else:\n",
        "        print(\"Input text is too long for summarization.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "id": "KdGAQoZ7WQAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from transformers import pipeline\n",
        "\n",
        "# Set your OpenAI API key here\n",
        "os.environ['OPENAI_API_KEY'] = \"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\"\n",
        "\n",
        "def main():\n",
        "    # Read PDF and extract text\n",
        "    pdfreader = PdfReader('Litrev.pdf')\n",
        "    raw_text = ''\n",
        "    for page in pdfreader.pages:\n",
        "        content = page.extract_text()\n",
        "        if content:\n",
        "            raw_text += content\n",
        "\n",
        "    # Split text using Character Text Split\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=800,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len,\n",
        "    )\n",
        "    texts = text_splitter.split_text(raw_text)\n",
        "\n",
        "    # Create embeddings with the API key\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=os.environ['OPENAI_API_KEY'])\n",
        "    document_search = FAISS.from_texts(texts, embeddings)\n",
        "\n",
        "    # Load question-answering chain\n",
        "    chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")\n",
        "\n",
        "    # Set up the summarization pipeline\n",
        "    summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\", do_sample=False)\n",
        "\n",
        "    print(\"Chatbot is ready. Type your query. Type 'bye' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"You: \")\n",
        "        if user_query.lower() == \"bye\":\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "        elif user_query.lower() == \"summary\":\n",
        "            chunk_summaries = []\n",
        "            for chunk in texts:\n",
        "                summary = summarizer(chunk, max_length=130, min_length=30)\n",
        "                chunk_summaries.append(summary[0]['summary_text'])\n",
        "            full_summary = \" \".join(chunk_summaries)\n",
        "            print(\"Chatbot: Summary of the entire PDF:\", full_summary)\n",
        "        else:\n",
        "            docs = document_search.similarity_search(user_query)\n",
        "            answer = chain.run(input_documents=docs, question=user_query)\n",
        "            print(\"Chatbot:\", answer)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "WTWw9SXdWRoY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "colab.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}